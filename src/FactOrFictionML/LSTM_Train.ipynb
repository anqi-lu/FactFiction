{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cntk as C\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import cntk.tests.test_utils\n",
    "cntk.tests.test_utils.set_device_from_pytest_env() # (only needed for our build system)\n",
    "C.cntk_py.set_fixed_random_seed(1) # fix a random seed for CNTK components\n",
    "%matplotlib inline\n",
    "\n",
    "azureml_share_env = 'AZUREML_NATIVE_SHARE_DIRECTORY'\n",
    "is_azure_ml = azureml_share_env in os.environ\n",
    "share_path = os.environ[azureml_share_env] if is_azure_ml else '../../'\n",
    "\n",
    "train_path = os.path.join(share_path, \"data/final/final.train.ctf\")\n",
    "val_path = os.path.join(share_path, \"data/final/final.val.ctf\")\n",
    "test_path = os.path.join(share_path, \"data/final/final.test.ctf\")\n",
    "\n",
    "print(C.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the reader\n",
    "def create_reader(path, is_training, input_dim, label_dim):\n",
    "    return C.io.MinibatchSource(C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "        features = C.io.StreamDef(field='S0', shape=input_dim,   is_sparse=True),\n",
    "        labels   = C.io.StreamDef(field='S1', shape=label_dim,   is_sparse=False)\n",
    "    )), randomize=is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)\n",
    "\n",
    "# Defines the LSTM model for classifying sequences\n",
    "def lstm_sequence_classifier(features, num_classes, embedding_dim, LSTM_dim):\n",
    "    classifier = C.layers.Sequential([C.layers.Embedding(embedding_dim, name='embed'),\n",
    "                                      C.layers.Recurrence(C.layers.LSTM(LSTM_dim), go_backwards=False),\n",
    "                                      C.sequence.last,\n",
    "                                      C.layers.Dense(num_classes, name='dense')])\n",
    "    return classifier(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoryTracker(C.logging.TrainingSummaryProgressCallback):\n",
    "    \n",
    "    def __init__(self, epoch_size):\n",
    "        def do_nothing():\n",
    "            pass\n",
    "        super(HistoryTracker, self).__init__(epoch_size, do_nothing)\n",
    "        self.train_history = []\n",
    "        self.test_history = []\n",
    "    \n",
    "    def on_write_training_summary(self, samples, updates, summaries, aggregate_loss, aggregate_metric, elapsed_milliseconds):\n",
    "        self.train_history.append(aggregate_metric*1.0/samples)\n",
    "        \n",
    "    def on_write_test_summary(self, samples, updates, summaries, aggregate_metric, elapsed_milliseconds):\n",
    "        self.test_history.append(aggregate_metric*1.0/samples)\n",
    "\n",
    "\n",
    "def train(reader, reader_val, model, loss, metric, max_epochs=10):\n",
    "    epoch_size = 9206 # Total number of sequences\n",
    "    minibatch_size = 300 # Minimum number of tokens being fetched in a minibatch\n",
    "\n",
    "    epoch_size_val = 1150\n",
    "\n",
    "    progress_printer = C.logging.ProgressPrinter(freq=150,\n",
    "                                                 tag='Training',\n",
    "                                                 num_epochs=max_epochs)\n",
    "    \n",
    "    # epoch_size*20 is the estimate of the total number of tokens\n",
    "    history_tracker = HistoryTracker(epoch_size*20)\n",
    "    \n",
    "    # SGD learner\n",
    "    #lr_per_sample = C.learners.learning_rate_schedule(0.0015, C.learners.UnitType.sample)\n",
    "    # learner = C.learners.sgd(model.parameters, lr=lr_per_sample)\n",
    "\n",
    "    lr_schedule = C.learning_parameter_schedule([1.0]*3 + [0.8]*2 + [0.6]*1,\n",
    "                                                 minibatch_size=C.learners.IGNORE,\n",
    "                                                 epoch_size=epoch_size)\n",
    "    t_schedule = C.momentum_schedule(0.971, minibatch_size=C.learners.IGNORE)\n",
    "    learner = adadelta = C.adadelta(model.parameters, lr_schedule, 0.999, 1e-6)\n",
    "\n",
    "    trainer = C.Trainer(model, (loss, metric),\n",
    "                        learner,\n",
    "                        [progress_printer, history_tracker])\n",
    "\n",
    "    input_map = {\n",
    "        features : reader.streams.features,\n",
    "        labels   : reader.streams.labels\n",
    "    }\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        # Train on one epoch\n",
    "        t = 0\n",
    "        while t < epoch_size:\n",
    "            mb = reader.next_minibatch(minibatch_size, input_map=input_map)\n",
    "            trainer.train_minibatch(mb)\n",
    "            t += mb[labels].num_samples # Current number of read sequences\n",
    "        trainer.summarize_training_progress()\n",
    "\n",
    "        # Evaluate validation set after one epoch\n",
    "        t = 0\n",
    "        while t < epoch_size_val:\n",
    "            mb = reader_val.next_minibatch(minibatch_size, input_map=input_map)\n",
    "            trainer.test_minibatch(mb)\n",
    "            t += mb[labels].num_samples\n",
    "\n",
    "        trainer.summarize_test_progress()\n",
    "    \n",
    "    return (history_tracker.train_history, history_tracker.test_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate per minibatch: 1.0\n",
      " Minibatch[   1- 150]: loss = 0.765841 * 1802, metric = 49.89% * 1802;\n",
      " Minibatch[ 151- 300]: loss = 0.723176 * 1809, metric = 47.82% * 1809;\n",
      " Minibatch[ 301- 450]: loss = 0.724666 * 1852, metric = 48.43% * 1852;\n",
      " Minibatch[ 451- 600]: loss = 0.660381 * 1823, metric = 35.44% * 1823;\n",
      " Minibatch[ 601- 750]: loss = 0.590198 * 1843, metric = 25.99% * 1843;\n",
      "Finished Epoch[1 of 10]: [Training] loss = 0.690416 * 9213, metric = 41.27% * 9213 46.400s (198.6 samples/s);\n",
      "Finished Evaluation [1]: Minibatch[1-95]: metric = 22.16% * 1155;\n",
      " Minibatch[   1- 150]: loss = 0.507305 * 1781, metric = 20.89% * 1781;\n",
      " Minibatch[ 151- 300]: loss = 0.514613 * 1826, metric = 23.06% * 1826;\n",
      " Minibatch[ 301- 450]: loss = 0.484044 * 1849, metric = 20.44% * 1849;\n",
      " Minibatch[ 451- 600]: loss = 0.501494 * 1815, metric = 21.21% * 1815;\n",
      " Minibatch[ 601- 750]: loss = 0.446122 * 1842, metric = 17.97% * 1842;\n",
      "Finished Epoch[2 of 10]: [Training] loss = 0.489118 * 9209, metric = 20.62% * 9209 49.382s (186.5 samples/s);\n",
      "Finished Evaluation [2]: Minibatch[1-95]: metric = 16.02% * 1155;\n",
      " Minibatch[   1- 150]: loss = 0.417499 * 1794, metric = 15.83% * 1794;\n",
      " Minibatch[ 151- 300]: loss = 0.379141 * 1839, metric = 14.95% * 1839;\n",
      " Minibatch[ 301- 450]: loss = 0.391119 * 1849, metric = 14.06% * 1849;\n",
      " Minibatch[ 451- 600]: loss = 0.325009 * 1807, metric = 11.95% * 1807;\n",
      " Minibatch[ 601- 750]: loss = 0.366889 * 1835, metric = 13.95% * 1835;\n",
      "Finished Epoch[3 of 10]: [Training] loss = 0.374767 * 9206, metric = 14.10% * 9206 49.329s (186.6 samples/s);\n",
      "Finished Evaluation [3]: Minibatch[1-95]: metric = 19.22% * 1160;\n",
      "Learning rate per minibatch: 0.8\n",
      " Minibatch[   1- 150]: loss = 0.248280 * 1805, metric = 8.31% * 1805;\n",
      " Minibatch[ 151- 300]: loss = 0.273338 * 1832, metric = 10.04% * 1832;\n",
      " Minibatch[ 301- 450]: loss = 0.253758 * 1825, metric = 9.37% * 1825;\n",
      " Minibatch[ 451- 600]: loss = 0.249435 * 1812, metric = 8.89% * 1812;\n",
      " Minibatch[ 601- 750]: loss = 0.286351 * 1828, metric = 9.41% * 1828;\n",
      "Finished Epoch[4 of 10]: [Training] loss = 0.261290 * 9209, metric = 9.15% * 9209 47.957s (192.0 samples/s);\n",
      "Finished Evaluation [4]: Minibatch[1-95]: metric = 11.84% * 1157;\n",
      " Minibatch[   1- 150]: loss = 0.185148 * 1853, metric = 6.15% * 1853;\n",
      " Minibatch[ 151- 300]: loss = 0.139826 * 1805, metric = 4.93% * 1805;\n",
      " Minibatch[ 301- 450]: loss = 0.166568 * 1833, metric = 5.02% * 1833;\n",
      " Minibatch[ 451- 600]: loss = 0.171915 * 1811, metric = 5.91% * 1811;\n",
      " Minibatch[ 601- 750]: loss = 0.138049 * 1805, metric = 4.38% * 1805;\n",
      "Learning rate per minibatch: 0.6\n",
      "Finished Epoch[5 of 10]: [Training] loss = 0.159648 * 9215, metric = 5.24% * 9215 48.803s (188.8 samples/s);\n",
      "Finished Evaluation [5]: Minibatch[1-95]: metric = 12.47% * 1163;\n",
      " Minibatch[   1- 150]: loss = 0.089344 * 1850, metric = 2.97% * 1850;\n",
      " Minibatch[ 151- 300]: loss = 0.063861 * 1806, metric = 1.77% * 1806;\n",
      " Minibatch[ 301- 450]: loss = 0.105702 * 1800, metric = 3.39% * 1800;\n",
      " Minibatch[ 451- 600]: loss = 0.083478 * 1839, metric = 2.45% * 1839;\n",
      " Minibatch[ 601- 750]: loss = 0.087788 * 1805, metric = 2.60% * 1805;\n",
      "Finished Epoch[6 of 10]: [Training] loss = 0.085748 * 9216, metric = 2.65% * 9216 45.360s (203.2 samples/s);\n",
      "Finished Evaluation [6]: Minibatch[1-96]: metric = 12.86% * 1159;\n",
      " Minibatch[   1- 150]: loss = 0.045139 * 1820, metric = 1.70% * 1820;\n",
      " Minibatch[ 151- 300]: loss = 0.068598 * 1819, metric = 2.25% * 1819;\n",
      " Minibatch[ 301- 450]: loss = 0.058375 * 1842, metric = 1.57% * 1842;\n",
      " Minibatch[ 451- 600]: loss = 0.047155 * 1808, metric = 1.05% * 1808;\n",
      " Minibatch[ 601- 750]: loss = 0.051907 * 1827, metric = 1.59% * 1827;\n",
      "Finished Epoch[7 of 10]: [Training] loss = 0.054150 * 9216, metric = 1.64% * 9216 49.037s (187.9 samples/s);\n",
      "Finished Evaluation [7]: Minibatch[1-95]: metric = 12.92% * 1153;\n",
      " Minibatch[   1- 150]: loss = 0.032102 * 1865, metric = 0.91% * 1865;\n",
      " Minibatch[ 151- 300]: loss = 0.041172 * 1839, metric = 1.09% * 1839;\n",
      " Minibatch[ 301- 450]: loss = 0.037468 * 1795, metric = 0.89% * 1795;\n",
      " Minibatch[ 451- 600]: loss = 0.044419 * 1826, metric = 1.15% * 1826;\n",
      " Minibatch[ 601- 750]: loss = 0.026060 * 1778, metric = 0.84% * 1778;\n",
      "Finished Epoch[8 of 10]: [Training] loss = 0.036012 * 9212, metric = 0.98% * 9212 49.841s (184.8 samples/s);\n",
      "Finished Evaluation [8]: Minibatch[1-96]: metric = 12.60% * 1159;\n",
      " Minibatch[   1- 150]: loss = 0.033967 * 1794, metric = 0.84% * 1794;\n",
      " Minibatch[ 151- 300]: loss = 0.015624 * 1806, metric = 0.50% * 1806;\n",
      " Minibatch[ 301- 450]: loss = 0.015793 * 1845, metric = 0.43% * 1845;\n",
      " Minibatch[ 451- 600]: loss = 0.022092 * 1855, metric = 0.54% * 1855;\n",
      " Minibatch[ 601- 750]: loss = 0.027759 * 1852, metric = 0.54% * 1852;\n",
      "Finished Epoch[9 of 10]: [Training] loss = 0.022868 * 9219, metric = 0.56% * 9219 48.778s (189.0 samples/s);\n",
      "Finished Evaluation [9]: Minibatch[1-94]: metric = 13.30% * 1150;\n",
      " Minibatch[   1- 150]: loss = 0.018069 * 1812, metric = 0.39% * 1812;\n",
      " Minibatch[ 151- 300]: loss = 0.019382 * 1826, metric = 0.44% * 1826;\n",
      " Minibatch[ 301- 450]: loss = 0.022197 * 1817, metric = 0.44% * 1817;\n",
      " Minibatch[ 451- 600]: loss = 0.012880 * 1830, metric = 0.33% * 1830;\n",
      " Minibatch[ 601- 750]: loss = 0.009302 * 1839, metric = 0.22% * 1839;\n",
      "Finished Epoch[10 of 10]: [Training] loss = 0.016190 * 9215, metric = 0.36% * 9215 49.748s (185.2 samples/s);\n",
      "Finished Evaluation [10]: Minibatch[1-95]: metric = 12.90% * 1155;\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 101590\n",
    "\n",
    "# Model dimensions\n",
    "input_dim = vocab_size\n",
    "hidden_dim = 500\n",
    "embedding_dim = 400\n",
    "num_classes = 3\n",
    "\n",
    "reader = create_reader(train_path, True, input_dim, num_classes)\n",
    "reader_val = create_reader(val_path, True, input_dim, num_classes)\n",
    "\n",
    "# Input variables denoting the features and label data\n",
    "features = C.sequence.input_variable(shape=input_dim, is_sparse=True)\n",
    "labels = C.input_variable(num_classes)\n",
    "\n",
    "# Instantiate the sequence classification model\n",
    "model_func = lstm_sequence_classifier(features, num_classes, embedding_dim, hidden_dim)\n",
    "model = model_func(features)\n",
    "\n",
    "# Create criterion\n",
    "loss        = C.cross_entropy_with_softmax(model, labels)\n",
    "label_error = C.classification_error(model, labels)\n",
    "\n",
    "history = train(reader, reader_val, model, loss, label_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c7355d2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(history[0], 'rx-', label='Train error')\n",
    "ax.plot(history[1], 'bo-', label='Validation error')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('error rate')\n",
    "ax.yaxis.grid('on')\n",
    "ax.legend()\n",
    "\n",
    "fig.savefig('outputs/train_history.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluation [1]: Minibatch[1-28]: metric = 13.99% * 1151;\n"
     ]
    }
   ],
   "source": [
    "reader_test = create_reader(val_path, False, input_dim, num_classes)\n",
    "\n",
    "test_minibatch_size = 1000\n",
    "\n",
    "input_map = {\n",
    "    features : reader.streams.features,\n",
    "    labels   : reader.streams.labels\n",
    "}\n",
    "\n",
    "progress_printer = C.logging.ProgressPrinter(tag='Evaluation', num_epochs=0)\n",
    "evaluator = C.eval.Evaluator(label_error, progress_printer)\n",
    "\n",
    "while True:\n",
    "    mb = reader_test.next_minibatch(test_minibatch_size, input_map=input_map)\n",
    "    if not mb:\n",
    "        break\n",
    "    eval_error = evaluator.test_minibatch(mb)\n",
    "\n",
    "evaluator.summarize_test_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'outputs/model.cmf'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mmlspark/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the punkt corpus first\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39853, 59425, 70309, 87407], [20052, 95297, 95074, 59425, 70309, 87407]]\n",
      "[[ 1.74848282 -0.71896964 -2.50516701]\n",
      " [-0.08711873  2.32584882 -2.38609338]]\n",
      "['objective', 'subjective']\n"
     ]
    }
   ],
   "source": [
    "from preprocess.normalize_sentences import SentenceNormalizer\n",
    "from cntk.ops.functions import load_model\n",
    "\n",
    "saved_model = load_model(model_path)\n",
    "vocab_size = 101590\n",
    "\n",
    "with open('dictionary.txt', 'r', encoding='utf-8') as f:\n",
    "    dictionary = f.read().strip().split('\\n') \n",
    "\n",
    "sent_normalizer = SentenceNormalizer(dictionary=dictionary)\n",
    "normalized = sent_normalizer.fit_transform(\n",
    "    [\"The earth is round\",\n",
    "     \"I think the earth is round\"], to_index=True)\n",
    "\n",
    "print(normalized)\n",
    "pred_score = saved_model(C.Value.one_hot(normalized, vocab_size))\n",
    "print(pred_score)\n",
    "\n",
    "pred_class = np.argmax(pred_score, axis=1)\n",
    "labels = []\n",
    "with open('labels.txt', 'r', encoding='utf-8') as f:\n",
    "    labels = f.read().strip().split('\\n')\n",
    "pred_class = [labels[p] for p in pred_class]\n",
    "print(pred_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
